{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51ec9a8-31bf-4024-ac19-6178c96a4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from lemminflect import getInflection, getAllInflections\n",
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c7ff68-092b-4708-89eb-9291af501806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tylercranmer/Dev/CSCI/Grad/NLP/NLP_2023/bert_vocab'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158daf96-bb2b-450a-b130-7127c8999834",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/tylercranmer/Dev/CSCI/Grad/NLP/NLP_2023/bert_vocab/words_alpha.txt', 'r') as file:\n",
    "    dictionary = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6384e05a-3307-441b-a17a-3dc47799f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/tylercranmer/Dev/CSCI/Grad/NLP/NLP_2023/bert_vocab/BERT-vocab.txt') as file:\n",
    "    burt_vocab = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90981b08-9872-4ddc-a98b-26103740880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of 30522\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of {len(burt_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f84a4eb-a5c6-4ca3-8e6e-fb65fa0e0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_brackets = [word for word in burt_vocab if not re.search(r'^\\[', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3009f64-8d06-41fa-9c2b-72344b5f2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 words removed.\n",
      "Current total 29522\n"
     ]
    }
   ],
   "source": [
    "rb_len = len(remove_brackets)\n",
    "total = len(burt_vocab)\n",
    "print(f\"{total - rb_len} words removed.\\nCurrent total {rb_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5979750a-f3ea-48bc-aca8-b51ed4c7a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_single_char = [word for word in remove_brackets if not re.search(r'^.$', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97ab65e4-48db-45fa-8670-31b8488ad881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996 words removed.\n",
      "Current total 28526\n"
     ]
    }
   ],
   "source": [
    "rsc_len = len(remove_single_char)\n",
    "print(f\"{rb_len - rsc_len} words removed.\\nCurrent total {rsc_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44fc603c-c230-4ce0-91c5-abff07d80b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_pound_char = [word for word in remove_single_char if not re.search(r'^##', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c7dc9d2-15f5-49df-9844-fd847b09e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5828 words removed.\n",
      "Current total 22698\n"
     ]
    }
   ],
   "source": [
    "rpc_len = len(remove_pound_char)\n",
    "print(f\"{rsc_len - rpc_len} words removed.\\nCurrent total {rpc_len}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ff28ea6-2591-4077-be16-d1d5ba471123",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_num = [word for word in remove_pound_char if not re.search(r'[0-9]+', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704b1e5e-7881-4037-8a76-e70df6cfe051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967 words removed.\n",
      "Current total 21731\n"
     ]
    }
   ],
   "source": [
    "rm_len = len(remove_num)\n",
    "print(f\"{rpc_len - rm_len} words removed.\\nCurrent total {rm_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3ad14a2-cbd9-45b0-bcef-786061d8a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_vowels = [word for word in remove_num if not re.search(r\"\\b[^aeiouy\\s]+\\b\", word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3f232fb-406c-4d3a-b68d-f4a8123485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_without_vowels = [word for word in remove_num if re.search(r\"\\b[^aeiouy\\s]+\\b\", word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80048744-7aa4-4c5d-9ebd-f2ec0cfbad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 words removed.\n",
      "Current total 21462\n"
     ]
    }
   ],
   "source": [
    "wwv_len = len(words_with_vowels)\n",
    "print(f\"{rm_len - wwv_len} words removed.\\nCurrent total {wwv_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ce846dd-e145-4490-920e-b794ee6a0332",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflections = []\n",
    "for w in words_with_vowels:\n",
    "    inflection_dic = getAllInflections(w)\n",
    "    for inflection_values in inflection_dic.values():\n",
    "        for inf_value in inflection_values:\n",
    "            if w != inf_value and inf_value in words_with_vowels:\n",
    "                inflections.append(inf_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ab1ef2b-b63f-4d58-9e39-33c68860d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_inflections = [word for word in words_with_vowels if word not in inflections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c30f630-a428-48be-94c6-5cd3dac2d349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5837 words removed.\n",
      "Current total 15625\n"
     ]
    }
   ],
   "source": [
    "no_inf_len = len(no_inflections)\n",
    "print(f\"{wwv_len - no_inf_len} words removed.\\nCurrent total {no_inf_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "555f28fb-f32c-49e5-b18b-449539c4b943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 words removed.\n",
      "Current total 15619\n"
     ]
    }
   ],
   "source": [
    "no_contraction = [word for word in no_inflections if word[-2:] != 'dn' and word[-2] != 'sn']\n",
    "no_nd_len = len(no_contraction)\n",
    "print(f\"{no_inf_len - no_nd_len} words removed.\\nCurrent total {no_nd_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3311a58d-0757-4c70-af48-52a86ab810f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "male_names = [name.lower() for name in male_names]\n",
    "female_names = [name.lower() for name in female_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "229b6313-715a-4961-9c16-3d2eec50f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477 words removed.\n",
      "Current total 14142\n"
     ]
    }
   ],
   "source": [
    "no_males = [word for word in no_contraction if word not in male_names]\n",
    "print(f\"{no_nd_len - len(no_males)} words removed.\\nCurrent total {len(no_males)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd7cd4c4-c38b-486b-8a51-0fb5f444c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680 words removed.\n",
      "Current total 13462\n"
     ]
    }
   ],
   "source": [
    "no_females = [word for word in no_males if word not in female_names]\n",
    "print(f\"{len(no_males) - len(no_females)} words removed.\\nCurrent total {len(no_females)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae03affb-a367-4117-a580-24f267b2ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 words removed.\n",
      "Current total 13332\n"
     ]
    }
   ],
   "source": [
    "no_lly = [word for word in no_females if not re.search(r\"(lly)$\", word) ]\n",
    "print(f\"{len(no_females) - len(no_lly)} words removed.\\nCurrent total {len(no_lly)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17264224-04c1-4f66-8586-072d4f5d32ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427 words removed.\n",
      "Final total 11905\n"
     ]
    }
   ],
   "source": [
    "final_list = [word for word in no_lly if word in dictionary]\n",
    "print(f\"{len(no_lly) - len(final_list)} words removed.\\nFinal total {len(final_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b5de95-f62a-417f-963f-2c8a090913df",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_dic_words = [word for word in no_lly if word not in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce2a5976-4edf-4b30-b521-a696408f3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2082e0ce-d27d-4bbf-b9f5-e12ba6ef623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem_words = [lemmatizer.lemmatize(word) for word in final_list]\n",
    "lem_words = list(set(lem_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4554fbee-7411-45e0-9cd4-2f04e1e26fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11790"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da45b725-baab-4c85-b666-f9db22210ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NNS': ('recalls', 'recall'),\n",
       " 'NN': ('recall',),\n",
       " 'VBD': ('recalled',),\n",
       " 'VBG': ('recalling',),\n",
       " 'VBZ': ('recalls',),\n",
       " 'VB': ('recall',),\n",
       " 'VBP': ('recall',)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = words_without_vowels[4568]\n",
    "getAllInflections('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14850fc-2f75-4731-bc28-9ac766d70a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdd34739-79ee-49b1-901a-8e3b6fc2811e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swallowed',\n",
       " 'patent',\n",
       " 'sara',\n",
       " 'illness',\n",
       " 'characterized',\n",
       " 'adventures',\n",
       " 'slide',\n",
       " 'hawaii',\n",
       " 'jurisdiction',\n",
       " 'organised',\n",
       " 'adelaide',\n",
       " 'walks',\n",
       " 'biology',\n",
       " 'se',\n",
       " 'rogers',\n",
       " 'swing',\n",
       " 'tightly',\n",
       " 'boundaries',\n",
       " 'prepare',\n",
       " 'implementation',\n",
       " 'stolen',\n",
       " 'certified',\n",
       " 'colombia',\n",
       " 'edwards',\n",
       " 'garage',\n",
       " 'recalled',\n",
       " 'rage',\n",
       " 'harm',\n",
       " 'nigeria',\n",
       " 'breast',\n",
       " 'furniture',\n",
       " 'pupils',\n",
       " 'settle',\n",
       " 'cuba',\n",
       " 'balls',\n",
       " 'client',\n",
       " 'alaska',\n",
       " 'linear',\n",
       " 'thrust',\n",
       " 'celebration',\n",
       " 'latino',\n",
       " 'genetic',\n",
       " 'terror',\n",
       " 'lightning',\n",
       " 'fee',\n",
       " 'witness',\n",
       " 'lodge',\n",
       " 'establishing',\n",
       " 'skull',\n",
       " 'earning',\n",
       " 'hood',\n",
       " 'rebellion',\n",
       " 'wang',\n",
       " 'sporting',\n",
       " 'warned',\n",
       " 'missile',\n",
       " 'devoted',\n",
       " 'activist',\n",
       " 'porch',\n",
       " 'worship',\n",
       " 'fourteen',\n",
       " 'package',\n",
       " 'decorated',\n",
       " 'housed',\n",
       " 'chess',\n",
       " 'sailed',\n",
       " 'doctors',\n",
       " 'oscar',\n",
       " 'joan',\n",
       " 'treat',\n",
       " 'garcia',\n",
       " 'harbour',\n",
       " 'jeremy',\n",
       " 'traditions',\n",
       " 'dominant',\n",
       " 'jacques',\n",
       " 'relocated',\n",
       " 'amendment',\n",
       " 'sized',\n",
       " 'companion',\n",
       " 'simultaneously',\n",
       " 'volleyball',\n",
       " 'spun',\n",
       " 'acre',\n",
       " 'increases',\n",
       " 'stopping',\n",
       " 'loves',\n",
       " 'belongs',\n",
       " 'affect',\n",
       " 'drafted',\n",
       " 'tossed',\n",
       " 'scout',\n",
       " 'battles',\n",
       " 'filming',\n",
       " 'shoved',\n",
       " 'munich',\n",
       " 'tenure',\n",
       " 'vertical',\n",
       " 'romance',\n",
       " 'argue',\n",
       " 'craft',\n",
       " 'ranging',\n",
       " 'opens',\n",
       " 'honest',\n",
       " 'tyler',\n",
       " 'yesterday',\n",
       " 'virtual',\n",
       " 'muslims',\n",
       " 'reveal',\n",
       " 'snake',\n",
       " 'immigrants',\n",
       " 'radical',\n",
       " 'screaming',\n",
       " 'speakers',\n",
       " 'firing',\n",
       " 'saving',\n",
       " 'belonging',\n",
       " 'ease',\n",
       " 'lighting',\n",
       " 'prefecture',\n",
       " 'blame',\n",
       " 'farmer',\n",
       " 'hungry',\n",
       " 'grows',\n",
       " 'rubbed',\n",
       " 'beam',\n",
       " 'sur',\n",
       " 'subsidiary',\n",
       " 'armenian',\n",
       " 'sao',\n",
       " 'dropping',\n",
       " 'conventional',\n",
       " 'microsoft',\n",
       " 'reply',\n",
       " 'qualify',\n",
       " 'spots',\n",
       " 'sweat',\n",
       " 'festivals',\n",
       " 'immigration',\n",
       " 'physician',\n",
       " 'discover',\n",
       " 'exposure',\n",
       " 'sandy',\n",
       " 'explanation',\n",
       " 'isaac',\n",
       " 'implemented',\n",
       " 'hart',\n",
       " 'initiated',\n",
       " 'connect',\n",
       " 'stakes',\n",
       " 'presents',\n",
       " 'heights',\n",
       " 'householder',\n",
       " 'pleased',\n",
       " 'tourist',\n",
       " 'regardless',\n",
       " 'slip',\n",
       " 'closest',\n",
       " 'surely',\n",
       " 'sultan',\n",
       " 'brings',\n",
       " 'riley',\n",
       " 'preparation',\n",
       " 'aboard',\n",
       " 'slammed',\n",
       " 'baptist',\n",
       " 'experiment',\n",
       " 'ongoing',\n",
       " 'interstate',\n",
       " 'organic',\n",
       " 'playoffs',\n",
       " 'hindu',\n",
       " 'error',\n",
       " 'tours',\n",
       " 'tier',\n",
       " 'plenty',\n",
       " 'arrangements',\n",
       " 'talks',\n",
       " 'trapped',\n",
       " 'excited',\n",
       " 'sank',\n",
       " 'ho',\n",
       " 'athens',\n",
       " 'denver',\n",
       " 'welfare',\n",
       " 'suburb',\n",
       " 'athletes',\n",
       " 'trick',\n",
       " 'diverse',\n",
       " 'belly',\n",
       " 'exclusively',\n",
       " 'yelled',\n",
       " 'conversion',\n",
       " 'internationally',\n",
       " 'computers',\n",
       " 'conductor',\n",
       " 'abilities',\n",
       " 'sensitive',\n",
       " 'hello',\n",
       " 'dispute',\n",
       " 'measured',\n",
       " 'globe',\n",
       " 'rocket',\n",
       " 'prices',\n",
       " 'amsterdam',\n",
       " 'flights',\n",
       " 'tigers',\n",
       " 'inn',\n",
       " 'municipalities',\n",
       " 'emotion',\n",
       " 'references',\n",
       " 'explains',\n",
       " 'airlines',\n",
       " 'manufactured',\n",
       " 'archaeological',\n",
       " 'interpretation',\n",
       " 'devon',\n",
       " 'comment',\n",
       " 'settlements',\n",
       " 'kissing',\n",
       " 'absolute',\n",
       " 'improvement',\n",
       " 'suite',\n",
       " 'impressed',\n",
       " 'barcelona',\n",
       " 'sullivan',\n",
       " 'jefferson',\n",
       " 'towers',\n",
       " 'jesse',\n",
       " 'julie',\n",
       " 'grandson',\n",
       " 'hi',\n",
       " 'gauge',\n",
       " 'regard',\n",
       " 'rings',\n",
       " 'interviews',\n",
       " 'trace',\n",
       " 'raymond',\n",
       " 'thumb',\n",
       " 'departments',\n",
       " 'burns',\n",
       " 'serial',\n",
       " 'bulgarian',\n",
       " 'scores',\n",
       " 'demonstrated',\n",
       " 'kyle',\n",
       " 'alberta',\n",
       " 'underneath',\n",
       " 'romanized',\n",
       " 'relieved',\n",
       " 'acquisition',\n",
       " 'phrase',\n",
       " 'cliff',\n",
       " 'reveals',\n",
       " 'han',\n",
       " 'cuts',\n",
       " 'merger',\n",
       " 'custom',\n",
       " 'nee',\n",
       " 'gilbert',\n",
       " 'graduation',\n",
       " 'assessment',\n",
       " 'cafe',\n",
       " 'difficulty',\n",
       " 'demands',\n",
       " 'swung',\n",
       " 'democrat',\n",
       " 'jennifer',\n",
       " 'commons',\n",
       " 'grove',\n",
       " 'completing',\n",
       " 'focuses',\n",
       " 'sum',\n",
       " 'substitute',\n",
       " 'bearing',\n",
       " 'stretch',\n",
       " 'reception',\n",
       " 'reflected',\n",
       " 'essentially',\n",
       " 'destination',\n",
       " 'pairs',\n",
       " 'survival',\n",
       " 'resource',\n",
       " 'promoting',\n",
       " 'doubles',\n",
       " 'messages',\n",
       " 'tear',\n",
       " 'parade',\n",
       " 'florence',\n",
       " 'harvey',\n",
       " 'incumbent',\n",
       " 'partial',\n",
       " 'framework',\n",
       " 'pedro',\n",
       " 'frozen',\n",
       " 'procedure',\n",
       " 'olivia',\n",
       " 'controls',\n",
       " 'shelter',\n",
       " 'personally',\n",
       " 'temperatures',\n",
       " 'brisbane',\n",
       " 'tested',\n",
       " 'sits',\n",
       " 'marble',\n",
       " 'comprehensive',\n",
       " 'oxygen',\n",
       " 'leonard',\n",
       " 'inaugural',\n",
       " 'iranian',\n",
       " 'referring',\n",
       " 'quarters',\n",
       " 'attitude',\n",
       " 'mainstream',\n",
       " 'lined',\n",
       " 'mars',\n",
       " 'dakota',\n",
       " 'norfolk',\n",
       " 'unsuccessful',\n",
       " 'explosion',\n",
       " 'helicopter',\n",
       " 'congressional',\n",
       " 'inspector',\n",
       " 'bitch',\n",
       " 'seal',\n",
       " 'departed',\n",
       " 'divine',\n",
       " 'coaching',\n",
       " 'examination',\n",
       " 'punishment',\n",
       " 'manufacturer',\n",
       " 'sink',\n",
       " 'columns',\n",
       " 'unincorporated',\n",
       " 'signals',\n",
       " 'nevada',\n",
       " 'squeezed',\n",
       " 'dylan',\n",
       " 'dining',\n",
       " 'photos',\n",
       " 'martial',\n",
       " 'manuel',\n",
       " 'eighteen',\n",
       " 'elevator',\n",
       " 'brushed',\n",
       " 'plates',\n",
       " 'ministers',\n",
       " 'ivy',\n",
       " 'congregation',\n",
       " 'slept',\n",
       " 'specialized',\n",
       " 'taxes',\n",
       " 'curve',\n",
       " 'restricted',\n",
       " 'negotiations',\n",
       " 'likes',\n",
       " 'statistical',\n",
       " 'arnold',\n",
       " 'inspiration',\n",
       " 'execution',\n",
       " 'bold',\n",
       " 'intermediate',\n",
       " 'significance',\n",
       " 'margin',\n",
       " 'ruler',\n",
       " 'wheels',\n",
       " 'gothic',\n",
       " 'intellectual',\n",
       " 'dependent',\n",
       " 'listened',\n",
       " 'eligible',\n",
       " 'buses',\n",
       " 'widow',\n",
       " 'syria',\n",
       " 'earn',\n",
       " 'cincinnati',\n",
       " 'collapsed',\n",
       " 'recipient',\n",
       " 'secrets',\n",
       " 'accessible',\n",
       " 'philippine',\n",
       " 'maritime',\n",
       " 'goddess',\n",
       " 'clerk',\n",
       " 'surrender',\n",
       " 'breaks',\n",
       " 'playoff',\n",
       " 'database',\n",
       " 'ideal',\n",
       " 'beetle',\n",
       " 'aspect',\n",
       " 'soap',\n",
       " 'regulation',\n",
       " 'strings',\n",
       " 'expand',\n",
       " 'anglo',\n",
       " 'shorter',\n",
       " 'crosses',\n",
       " 'retreat',\n",
       " 'tough',\n",
       " 'coins',\n",
       " 'wallace',\n",
       " 'directions',\n",
       " 'pressing',\n",
       " 'shipping',\n",
       " 'locomotives',\n",
       " 'comparison',\n",
       " 'topics',\n",
       " 'nephew',\n",
       " 'distinction',\n",
       " 'honors',\n",
       " 'travelled',\n",
       " 'sierra',\n",
       " 'ibn',\n",
       " 'fortress',\n",
       " 'sa',\n",
       " 'recognised',\n",
       " 'carved',\n",
       " 'clients',\n",
       " 'intent',\n",
       " 'coaches',\n",
       " 'describing',\n",
       " 'bread',\n",
       " 'beaten',\n",
       " 'northwestern',\n",
       " 'merit',\n",
       " 'youtube',\n",
       " 'collapse',\n",
       " 'challenges',\n",
       " 'em',\n",
       " 'historians',\n",
       " 'objective']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_without_vowels[4568:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ff6bf-5092-4d7e-a846-d5502cb483de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roughly see around ~11905 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cad2f-ce4a-44c7-ba1f-8bb96e4a8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb96f48-38d2-49ff-8c1f-72060537ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in words_without_vowels:\n",
    "#     matches = process.extract(w, is_word, limit = 10)\n",
    "#     top_matches = [match[0] for match in matches if match[0] != w]\n",
    "#     print(f\"Top matches for {w}: {top_matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150ae1d-89a5-4421-8858-83d13ac3febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in words_without_vowels:\n",
    "#     matches = process.extract(w, words_without_vowels, limit = 10)\n",
    "#     top_matches = [match[0] for match in matches if match[0] != w]\n",
    "#     print(f\"Top matches for {w}: {top_matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f7036-7d7d-4cf4-8ef7-5e99aa2e046e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
